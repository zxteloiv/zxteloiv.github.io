---
layout: page
title: 2016.11.29 Notes Query Reduction Networks for QA
math_support: mathjax
---


## introductionQUERY-REDUCTION NETWORKS FOR QUESTION ANSWERINGsubmitted to ICLR-2017Minjoon Seo 1, Sewon Min 3, Ali Farhadi 1,2 & Hannaneh Hajishirzi 1University of Washington 1,Allen Institute for Artificial Intelligence 2,Seoul National University 3{minjoon, ali, hannaneh}@cs.washington.edu, shmsw25@snu.ac.kr**Target**:Reasoning over multiple fact questions:> Frogs eat insects.  > Flies are insects.  > Do frogs eat flies?*"standard attention mechanisms are insensitive to the time step (memory address) of the sentences when accessing them"*## modelQuery-Reduction Network (QRN)- considers the context sentences as a sequence of state-changing triggers- reduces the original query to an easier-to-answer queryModel Overview:1. Input: sentence $x_t$ and question $q_t$ encoding 2. **QRN Layer**: predict answer $\hat y\in R^{d}$3. Output: $\hat y \to$ natural language answer![QQ20161129-3.png](resources/2D8E93595E4CDE25BA2C8FEE4A19B2EC.png)### QRN Layer:A variant of RNN unit- update gate: $$z_t = \alpha(x_t, q_t) = \sigma(W^{(z)}(x_t\circ q_t)+b^{(z)})$$- reduce query: $$\tilde{h_t} = \rho(x_t, q_t) = \tanh(W^{(h)}[x_t;q_t]+b^{(h)})$$- hidden: $$h_t = z_t\tilde{h_t} + (1-z_t)h_{t-1}$$![QQ20161129-0.png](resources/D2B7F9A853D44F461CA0F1850092CF08.png)Stacked Layer:- next layer q: $$q^{k+1}_t = \overrightarrow{h}_t^k$$- next layer q bi-direction: $$q^{k+1}_t = \overrightarrow{h}_t^k + \overleftarrow{h}_t^k$$- next layer x: $$x^{k+1} = x^{k}$$![QQ20161129-4.png](resources/671FF9F2ED4F1ECF19F42BF053554579.png)#### Extension:Reset gate:- $$r_t = \beta(x_t, q_t) = \sigma(W^{(r)}(x_t\circ q_t)+b^{(r)})$$- Hidden: $$h_t = z_t r_t \tilde{h_t} + (1-z_t)h_{t-1}$$Vector gates: both update gate and reset gate is replace as a vector## Parallelizationunrolled hidden states: ![QQ20161129-1.png](resources/FF64ED44FB8D8BD7F0D2E8A49BC84B63.png)Vectorized (for all time step t):![QQ20161129-2.png](resources/AA4206E447BC4D58291199124600DB9A.png)## implementation**input module**: Position Encoder (Weston et al., 2015 (Memory Networks))**output module**:- story-based QA: V-class single-layer softmax (multi-word answer included)- dialog: RNN decoder (Cho et al. 2014), w/o recurrent hidden states and attention**result**![QQ20161129-5.png](resources/B1FFD1242D29331A2BBEBAFBFC9B5879.png)![QQ20161129-6.png](resources/832FC88EDBEAF57252382EC90918B4DD.png)![QQ20161129-7.png](resources/D3227B01CFB68996EBE0F3B06A05722B.png)


